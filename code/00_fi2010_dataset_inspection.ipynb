{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61b9a747-f594-480b-b740-0deef857a548",
   "metadata": {},
   "source": [
    "# FI-2010 Dataset Inspection and Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03f1c56-0860-41a0-a175-6117f9be93ca",
   "metadata": {},
   "source": [
    "This notebook performs a systematic inspection and validation of the FI-2010 dataset\n",
    "used in the thesis.\n",
    "\n",
    "The goal is to verify the structural integrity, feature composition, label definitions,\n",
    "normalization properties, and train/test split consistency of the dataset, without making\n",
    "any assumptions beyond what can be empirically confirmed from the data itself.\n",
    "\n",
    "All findings reported here directly inform Chapter 4 (Problem Formulation and Data) of\n",
    "the thesis. The notebook is not used for model training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572fe17e-d54b-4ca0-a23e-318e16e3fa5c",
   "metadata": {},
   "source": [
    "## 1. Imports, Setup, and Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1a88bf5e-32bf-4c8e-9b34-1d95a0b1f4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /Users/luisreindlmeier\n",
      "Python: 3.11.14\n",
      "Platform: macOS-26.1-arm64-arm-64bit\n",
      "pandas: 2.3.3\n",
      "numpy: 2.4.0\n",
      "------------------------------\n",
      "Train dataset shape: (362400, 150)\n",
      "Test dataset shape: (31937, 150)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys, platform\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path().resolve().parents[2]\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "print(\"Project root:\", PROJECT_ROOT)\n",
    "\n",
    "# Versioning\n",
    "print(\"Python:\", sys.version.split()[0])\n",
    "print(\"Platform:\", platform.platform())\n",
    "print(\"pandas:\", pd.__version__)\n",
    "print(\"numpy:\", np.__version__)\n",
    "\n",
    "print(\"-\" * 30)\n",
    "\n",
    "train_path = \"../data/FI-2010/train.csv\"\n",
    "test_path  = \"../data/FI-2010/test.csv\"\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df  = pd.read_csv(test_path)\n",
    "\n",
    "# Shapes\n",
    "print(\"Train dataset shape:\", train_df.shape)\n",
    "print(\"Test dataset shape:\", test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973a2721-d509-4cdc-84e8-76d384c7b522",
   "metadata": {},
   "source": [
    "## 2. Structural Integrity Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53cf2e5-bdd5-49b8-85fa-d191feb81fe7",
   "metadata": {},
   "source": [
    "### 2.1 Column Count & Index Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a6cd72e7-b101-4940-a53b-9e693a394e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 columns (raw): ['Unnamed: 0', '0', '1', '2', '3', '4', '5', '6', '7', '8']\n",
      "Last 10 columns  (raw): ['139', '140', '141', '142', '143', '144', '145', '146', '147', '148']\n",
      "Train shape (clean): (362400, 149)\n",
      "Test shape  (clean): (31937, 149)\n"
     ]
    }
   ],
   "source": [
    "# Show first/last columns\n",
    "print(\"First 10 columns (raw):\", list(train_df.columns[:10]))\n",
    "print(\"Last 10 columns  (raw):\", list(train_df.columns[-10:]))\n",
    "\n",
    "# Drop index column if present\n",
    "if \"Unnamed: 0\" in train_df.columns:\n",
    "    train_df = train_df.drop(columns=[\"Unnamed: 0\"])\n",
    "    test_df  = test_df.drop(columns=[\"Unnamed: 0\"])\n",
    "\n",
    "print(\"Train shape (clean):\", train_df.shape)\n",
    "print(\"Test shape  (clean):\", test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89eb7974-c56f-4a92-b838-044ec229937d",
   "metadata": {},
   "source": [
    "### 2.2 Feature / Label Separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "deb00e74-e994-4f4f-9ba5-0835668542c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 5 rows × first 5 feature columns:\n",
      "          0         1         2         3         4\n",
      "0  0.318116 -0.564619  0.313539 -0.551889  0.319726\n",
      "1  0.318116 -0.662079  0.313539 -0.551889  0.320706\n",
      "2  0.317136 -0.723163  0.313539 -0.551889  0.316787\n",
      "3  0.317136 -0.585895  0.313539 -0.551889  0.318747\n",
      "4  0.317136 -0.585895  0.313539 -0.551889  0.318747\n",
      "\n",
      "First 5 rows × last 5 feature columns:\n",
      "        139       140  141  142  143\n",
      "0 -0.816832 -0.825238  0.0  0.0  0.0\n",
      "1  0.464300  0.452887  0.0  0.0  0.0\n",
      "2 -0.798788 -0.807237  0.0  0.0  0.0\n",
      "3  0.465974  0.454558  0.0  0.0  0.0\n",
      "4 -0.410306 -0.419666  0.0  0.0  0.0\n",
      "\n",
      "First 5 rows × all label columns:\n",
      "   144  145  146  147  148\n",
      "0  2.0  2.0  2.0  2.0  2.0\n",
      "1  2.0  2.0  2.0  2.0  2.0\n",
      "2  3.0  3.0  2.0  2.0  2.0\n",
      "3  2.0  2.0  3.0  2.0  2.0\n",
      "4  1.0  1.0  1.0  2.0  2.0\n"
     ]
    }
   ],
   "source": [
    "# Create feature / label separation\n",
    "X_train = train_df.iloc[:, :-5]\n",
    "y_train = train_df.iloc[:, -5:]\n",
    "\n",
    "X_test  = test_df.iloc[:, :-5]\n",
    "y_test  = test_df.iloc[:, -5:]\n",
    "\n",
    "feature_col = X_train.columns[0]\n",
    "\n",
    "# Manual raw values inspection (validate the split)\n",
    "print(\"\\nFirst 5 rows × first 5 feature columns:\")\n",
    "print(X_train.iloc[:5, :5])\n",
    "\n",
    "print(\"\\nFirst 5 rows × last 5 feature columns:\")\n",
    "print(X_train.iloc[:5, -5:])\n",
    "\n",
    "print(\"\\nFirst 5 rows × all label columns:\")\n",
    "print(y_train.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0641f14e-1139-4384-82e6-28473837ee50",
   "metadata": {},
   "source": [
    "## 3. Feature Space Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0daaef67-9fe6-48df-a187-a0620c102e48",
   "metadata": {},
   "source": [
    "### 3.1 Feature Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bf791966-85a4-412f-9c4c-8f077dc96ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature columns: 144\n",
      "------------------------------\n",
      "Feature column statistics:\n",
      "count    3.624000e+05\n",
      "mean    -1.591887e-10\n",
      "std      1.000000e+00\n",
      "min     -1.065622e+00\n",
      "25%     -9.833034e-01\n",
      "50%     -5.266306e-01\n",
      "75%      1.156003e+00\n",
      "max      1.355919e+00\n",
      "Name: 0, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Feature columns:\", X_train.shape[1])\n",
    "\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Expecting features are normalized (mean≈0, std≈1)\n",
    "print(\"Feature column statistics:\")\n",
    "print(X_train[feature_col].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06948d1b-8851-49c7-bc7d-3af97a52c2b3",
   "metadata": {},
   "source": [
    "### 3.2 Normalization Sanity Check (z-score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d217184c-d9e7-40eb-9d38-d0e10fedbc13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max |feature mean|: 7.92e-09\n",
      "Max |feature std - 1|: 1.00e+00\n"
     ]
    }
   ],
   "source": [
    "# Normalization sanity check (z-score)\n",
    "stats = X_train.describe().loc[[\"mean\", \"std\"]]\n",
    "stats.iloc[:, :10]\n",
    "\n",
    "mean_max = stats.loc[\"mean\"].abs().max()\n",
    "std_max_deviation = stats.loc[\"std\"].sub(1).abs().max()\n",
    "\n",
    "print(f\"Max |feature mean|: {mean_max:.2e}\")\n",
    "print(f\"Max |feature std - 1|: {std_max_deviation:.2e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bd468d-6fa4-412e-8f40-cb542451e66b",
   "metadata": {},
   "source": [
    "### 3.3 Missing / Invalid Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "57f2375f-d720-408f-8d90-b4d1cca99b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN values in features: 0\n",
      "Infinite values: 0\n"
     ]
    }
   ],
   "source": [
    "n_nan = np.isnan(X_train.values).sum()\n",
    "n_inf = np.isinf(X_train.values).sum()\n",
    "\n",
    "print(f\"NaN values in features: {n_nan}\")\n",
    "print(f\"Infinite values: {n_inf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214968e9-aa31-46b5-abcf-0794ebfd4a81",
   "metadata": {},
   "source": [
    "## 4. Label Definition & Semantics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc4c97f-7b14-4590-988d-fcd5e62a9158",
   "metadata": {},
   "source": [
    "### 4.1 Label Horizons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fa4015f9-0c37-4aad-a008-0321097093b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label colums: ['144', '145', '146', '147', '148']\n",
      "------------------------------\n",
      "Label column statistics:\n",
      "count    362400.000000\n",
      "mean          1.997599\n",
      "std           0.600984\n",
      "min           1.000000\n",
      "25%           2.000000\n",
      "50%           2.000000\n",
      "75%           2.000000\n",
      "max           3.000000\n",
      "Name: 144, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# According to FI-2010 specification, columns 144–148 correspond to prediction horizons h ∈ {10,20,30,50,100}\n",
    "print(\"Label colums:\", list(y_train.columns))\n",
    "\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Expecting labels mean≈2 (only values 1,2,3, wiith 0 and 2 showing a similar frequency), min=1, and max=3\n",
    "print(\"Label column statistics:\")\n",
    "print(y_train.iloc[:, 0].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc58b79c-7c14-4367-ac51-9e23b780cc13",
   "metadata": {},
   "source": [
    "### 4.2 Raw Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "045875ca-02d8-4554-b2a5-9ca3a11f2939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 2. 3.]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(y_train.iloc[:, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be215820-96da-494a-905f-197429cffbea",
   "metadata": {},
   "source": [
    "### 4.3 Label Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f5e6bd04-984f-470d-a921-a254a7eafebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Label Distribution for column 144\n",
      "1.0    0.181794\n",
      "2.0    0.638813\n",
      "3.0    0.179393\n",
      "Name: proportion, dtype: float64\n",
      "------------------------------\n",
      "Test Label Distribution for column 144\n",
      "1.0    0.173686\n",
      "2.0    0.668159\n",
      "3.0    0.158155\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "train_dist = y_train.iloc[:, 0].value_counts(normalize=True).sort_index()\n",
    "test_dist  = y_test.iloc[:, 0].value_counts(normalize=True).sort_index()\n",
    "\n",
    "print(\"Train Label Distribution for column\", train_dist)\n",
    "\n",
    "print(\"-\" * 30)\n",
    "\n",
    "print(\"Test Label Distribution for column\", test_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b1f92d-e990-447d-a78d-dc4b830b25c9",
   "metadata": {},
   "source": [
    "### 4.4 Mapping to {-1, 0, +1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "40892a23-8415-44fb-b077-d30ff63b9338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping for column 144\n",
      "-1     65882\n",
      " 0    231506\n",
      " 1     65012\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Select horizon h = 10 (first label column)\n",
    "h10 = y_train.iloc[:, 0]\n",
    "\n",
    "# FI-2010 labels use encoding {1: down, 2: stationary, 3: up}\n",
    "label_mapping = {\n",
    "    1: -1,  # downward\n",
    "    2:  0,  # stationary\n",
    "    3:  1   # upward\n",
    "}\n",
    "\n",
    "y_train_h10_mapped = h10.map(label_mapping)\n",
    "\n",
    "print(\"Mapping for column\", y_train_h10_mapped.value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9730f5dc-4cdb-4713-b750-678007782c6c",
   "metadata": {},
   "source": [
    "## 5. Dataset Summary (for Thesis Reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f8eaa307-3361-4d32-be89-bf4c9a69af08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "DATASET SUMMARY\n",
      "==================================================\n",
      "\n",
      "Sample sizes\n",
      "Train samples                 : 362400\n",
      "Test samples                  : 31937\n",
      "Train/Test split ratio        : 0.919\n",
      "--------------------------------------------------\n",
      "\n",
      "Feature space\n",
      "LOB feature dimension         : 144\n",
      "--------------------------------------------------\n",
      "\n",
      "Labels\n",
      "Number of label horizons      : 5\n",
      "Label horizons (columns)      : ['144', '145', '146', '147', '148']\n",
      "Raw label values              : [np.int64(1), np.int64(2), np.int64(3)]\n",
      "Label encoding (raw)          : {1: 'downward', 2: 'stationary', 3: 'upward'}\n",
      "--------------------------------------------------\n",
      "\n",
      "Normalization checks\n",
      "Feature normalization         : z-score (mean≈0, std≈1)\n",
      "Max |feature mean|            : 7.92e-09\n",
      "Max |feature std − 1|         : 1.00e+00\n",
      "--------------------------------------------------\n",
      "\n",
      "Data integrity\n",
      "Missing values (features)     : 0\n",
      "Infinite values (features)    : 0\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Calculate dataset summary metrics\n",
    "n_train = X_train.shape[0]\n",
    "n_test = X_test.shape[0]\n",
    "train_ratio = n_train / (n_train + n_test)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"DATASET SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"\\nSample sizes\")\n",
    "print(f\"{'Train samples':<30}: {n_train}\")\n",
    "print(f\"{'Test samples':<30}: {n_test}\")\n",
    "print(f\"{'Train/Test split ratio':<30}: {round(train_ratio, 4)}\")\n",
    "\n",
    "print(\"-\" * 50)\n",
    "\n",
    "print(\"\\nFeature space\")\n",
    "print(f\"{'LOB feature dimension':<30}: {X_train.shape[1]}\")\n",
    "\n",
    "print(\"-\" * 50)\n",
    "\n",
    "print(\"\\nLabels\")\n",
    "print(f\"{'Number of label horizons':<30}: {y_train.shape[1]}\")\n",
    "print(f\"{'Label horizons (columns)':<30}: {list(y_train.columns)}\")\n",
    "print(f\"{'Raw label values':<30}: {sorted(y_train.iloc[:, 0].unique().astype(int))}\")\n",
    "print(f\"{'Label encoding (raw)':<30}: {{1: 'downward', 2: 'stationary', 3: 'upward'}}\")\n",
    "\n",
    "print(\"-\" * 50)\n",
    "\n",
    "print(\"\\nNormalization checks\")\n",
    "print(f\"{'Feature normalization':<30}: z-score (mean≈0, std≈1)\")\n",
    "print(f\"{'Max |feature mean|':<30}: {stats.loc['mean'].abs().max():.2e}\")\n",
    "print(f\"{'Max |feature std − 1|':<30}: {stats.loc['std'].sub(1).abs().max():.2e}\")\n",
    "\n",
    "print(\"-\" * 50)\n",
    "\n",
    "print(\"\\nData integrity\")\n",
    "print(f\"{'Missing values (features)':<30}: {int(np.isnan(X_train.values).sum())}\")\n",
    "print(f\"{'Infinite values (features)':<30}: {int(np.isinf(X_train.values).sum())}\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39ef10f-9151-4ae6-bf6b-530d0806c196",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84c9ed31",
   "metadata": {},
   "source": [
    "## 6. Important Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08097d42",
   "metadata": {},
   "source": [
    "## Check 1 – Class Distribution (Train vs Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dac7cc70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144\n",
      "1.0     65882\n",
      "2.0    231506\n",
      "3.0     65012\n",
      "Name: count, dtype: int64\n",
      "144\n",
      "1.0     5547\n",
      "2.0    21339\n",
      "3.0     5051\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_train.iloc[:, 0].value_counts().sort_index())\n",
    "print(y_test.iloc[:, 0].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7cab1a",
   "metadata": {},
   "source": [
    "## Check 2 – Confusion Matrix (After Short Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1b8a01c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>pred</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2847</td>\n",
       "      <td>1440</td>\n",
       "      <td>1260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12168</td>\n",
       "      <td>4378</td>\n",
       "      <td>4793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2581</td>\n",
       "      <td>1266</td>\n",
       "      <td>1204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "pred      0     1     2\n",
       "true                   \n",
       "0      2847  1440  1260\n",
       "1     12168  4378  4793\n",
       "2      2581  1266  1204"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datasets.fi2010 import FI2010Dataset\n",
    "from models.model import LOBTransformer\n",
    "\n",
    "DEVICE = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "\n",
    "# 1) Dataset + Loader (h=10 => first label column 144)\n",
    "test_ds = FI2010Dataset(csv_path=\"../data/FI-2010/test.csv\", horizon_idx=0)  \n",
    "test_loader = torch.utils.data.DataLoader(test_ds, batch_size=1024, shuffle=False)\n",
    "\n",
    "# 2) Load model\n",
    "model = LOBTransformer().to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "# 3) Create preds\n",
    "all_preds = []\n",
    "all_true = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader:\n",
    "        x = x.to(DEVICE)\n",
    "        y = y.to(DEVICE)\n",
    "\n",
    "        logits = model(x)\n",
    "        pred = torch.argmax(logits, dim=1)\n",
    "\n",
    "        all_preds.append(pred.cpu().numpy())\n",
    "        all_true.append(y.cpu().numpy())\n",
    "\n",
    "y_pred = np.concatenate(all_preds)\n",
    "y_true = np.concatenate(all_true)\n",
    "\n",
    "# 4) Confusion matrix (Labels 0/1/2)\n",
    "cm = pd.crosstab(\n",
    "    pd.Series(y_true, name=\"true\"),\n",
    "    pd.Series(y_pred, name=\"pred\"),\n",
    "    rownames=[\"true\"], colnames=[\"pred\"],\n",
    "    dropna=False\n",
    ")\n",
    "\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409db1fc",
   "metadata": {},
   "source": [
    "## Check 3 – Shuffle Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfbfdfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38cd1067",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e34b7617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "FINAL MODEL EVALUATION (h = 10)\n",
      "============================================================\n",
      "\n",
      "Label value sanity check\n",
      "------------------------------\n",
      "Unique true labels : [0 1 2]\n",
      "Unique pred labels : [0 1 2]\n",
      "\n",
      "Accuracy\n",
      "------------------------------\n",
      "Accuracy: 0.2639\n",
      "\n",
      "Macro F1-score\n",
      "------------------------------\n",
      "Macro F1: 0.2499\n",
      "\n",
      "Per-class precision / recall / F1\n",
      "------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        down     0.1618    0.5133    0.2460      5547\n",
      "  stationary     0.6180    0.2052    0.3081     21339\n",
      "          up     0.1659    0.2384    0.1956      5051\n",
      "\n",
      "    accuracy                         0.2639     31937\n",
      "   macro avg     0.3152    0.3189    0.2499     31937\n",
      "weighted avg     0.4673    0.2639    0.2795     31937\n",
      "\n",
      "\n",
      "Normalized confusion matrix (row-wise)\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>pred</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.513250</td>\n",
       "      <td>0.259600</td>\n",
       "      <td>0.227150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.570224</td>\n",
       "      <td>0.205164</td>\n",
       "      <td>0.224612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.510988</td>\n",
       "      <td>0.250643</td>\n",
       "      <td>0.238369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "pred         0         1         2\n",
       "true                              \n",
       "0     0.513250  0.259600  0.227150\n",
       "1     0.570224  0.205164  0.224612\n",
       "2     0.510988  0.250643  0.238369"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# FINAL EVALUATION CHECKS (h = 10)\n",
    "# ============================================================\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    classification_report\n",
    ")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"FINAL MODEL EVALUATION (h = 10)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1) Sanity check: label ranges\n",
    "# ------------------------------------------------------------\n",
    "print(\"\\nLabel value sanity check\")\n",
    "print(\"-\" * 30)\n",
    "print(\"Unique true labels :\", np.unique(y_true))\n",
    "print(\"Unique pred labels :\", np.unique(y_pred))\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2) Accuracy (for reference only)\n",
    "# ------------------------------------------------------------\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "\n",
    "print(\"\\nAccuracy\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3) Macro F1 (MAIN METRIC)\n",
    "# ------------------------------------------------------------\n",
    "macro_f1 = f1_score(y_true, y_pred, average=\"macro\")\n",
    "\n",
    "print(\"\\nMacro F1-score\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"Macro F1: {macro_f1:.4f}\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4) Detailed per-class metrics\n",
    "# ------------------------------------------------------------\n",
    "print(\"\\nPer-class precision / recall / F1\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "print(\n",
    "    classification_report(\n",
    "        y_true,\n",
    "        y_pred,\n",
    "        target_names=[\"down\", \"stationary\", \"up\"],\n",
    "        digits=4\n",
    "    )\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5) Normalized confusion matrix (optional but useful)\n",
    "# ------------------------------------------------------------\n",
    "print(\"\\nNormalized confusion matrix (row-wise)\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "cm_norm = cm.div(cm.sum(axis=1), axis=0)\n",
    "cm_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e847297",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d712378",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc36771a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62eabb54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (thesis-venv)",
   "language": "python",
   "name": "thesis-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
